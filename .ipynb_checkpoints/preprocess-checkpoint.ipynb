{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "257955d4-275d-4830-8cca-4ddd7086472c",
   "metadata": {},
   "source": [
    "# Intel RealSense Video to Gaussian-Splatting NeRF Preprocessing Pipeline\n",
    "\n",
    "Warning!!! The following cell is some syntactic sugar to automate install process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "967cea9f-585d-4532-84a4-b8e1cb9fdbf2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2025-04-11 16:43:10--  https://github.com/IntelRealSense/librealsense/raw/master/scripts/libuvc_installation.sh\n",
      "Resolving github.com (github.com)... 4.208.26.197\n",
      "Connecting to github.com (github.com)|4.208.26.197|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/IntelRealSense/librealsense/master/scripts/libuvc_installation.sh [following]\n",
      "--2025-04-11 16:43:10--  https://raw.githubusercontent.com/IntelRealSense/librealsense/master/scripts/libuvc_installation.sh\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1359 (1.3K) [text/plain]\n",
      "Saving to: ‘libuvc_installation.sh.1’\n",
      "\n",
      "     0K .                                                     100%  184M=0s\n",
      "\n",
      "2025-04-11 16:43:10 (184 MB/s) - ‘libuvc_installation.sh.1’ saved [1359/1359]\n",
      "\n",
      "+ exec\n",
      "+ exec\n",
      "+ '[' 0 -ne 0 ']'\n",
      "+ lsb_release -a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n",
      "Distributor ID:\tUbuntu\n",
      "Description:\tUbuntu 24.04.2 LTS\n",
      "Release:\t24.04\n",
      "Codename:\tnoble\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "++ uname -r\n",
      "+ echo 'Kernel version 6.11.0-19-generic'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel version 6.11.0-19-generic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ sudo apt-get update\n",
      "sudo: a terminal is required to read the password; either use the -S option to read from standard input or configure an askpass helper\n",
      "sudo: a password is required\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement pyrealsense2 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for pyrealsense2\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'# Download the librealsense installation script\\nwget https://github.com/IntelRealSense/librealsense/raw/master/scripts/libuvc_installation.sh\\nchmod +x ./libuvc_installation.sh\\n\\n# Run the installation script with Python bindings enabled\\n./libuvc_installation.sh -DBUILD_PYTHON_BINDINGS:bool=true\\n\\n# Install Python dependencies from requirements.txt\\npip install -r requirements.txt\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCalledProcessError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbash\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m# Download the librealsense installation script\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mwget https://github.com/IntelRealSense/librealsense/raw/master/scripts/libuvc_installation.sh\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mchmod +x ./libuvc_installation.sh\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m# Run the installation script with Python bindings enabled\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m./libuvc_installation.sh -DBUILD_PYTHON_BINDINGS:bool=true\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m# Install Python dependencies from requirements.txt\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mpip install -r requirements.txt\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2547\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2545\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m   2546\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2547\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2549\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2550\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2551\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2552\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/IPython/core/magics/script.py:159\u001b[39m, in \u001b[36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[39m\u001b[34m(line, cell)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    158\u001b[39m     line = script\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshebang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/IPython/core/magics/script.py:336\u001b[39m, in \u001b[36mScriptMagics.shebang\u001b[39m\u001b[34m(self, line, cell)\u001b[39m\n\u001b[32m    331\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args.raise_error \u001b[38;5;129;01mand\u001b[39;00m p.returncode != \u001b[32m0\u001b[39m:\n\u001b[32m    332\u001b[39m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[32m    333\u001b[39m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[32m    334\u001b[39m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[32m    335\u001b[39m     rc = p.returncode \u001b[38;5;129;01mor\u001b[39;00m -\u001b[32m9\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[31mCalledProcessError\u001b[39m: Command 'b'# Download the librealsense installation script\\nwget https://github.com/IntelRealSense/librealsense/raw/master/scripts/libuvc_installation.sh\\nchmod +x ./libuvc_installation.sh\\n\\n# Run the installation script with Python bindings enabled\\n./libuvc_installation.sh -DBUILD_PYTHON_BINDINGS:bool=true\\n\\n# Install Python dependencies from requirements.txt\\npip install -r requirements.txt\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Download the librealsense installation script\n",
    "wget https://github.com/IntelRealSense/librealsense/raw/master/scripts/libuvc_installation.sh\n",
    "chmod +x ./libuvc_installation.sh\n",
    "\n",
    "# Run the installation script with Python bindings enabled\n",
    "./libuvc_installation.sh -DBUILD_PYTHON_BINDINGS:bool=true\n",
    "\n",
    "# Install Python dependencies from requirements.txt\n",
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3948f410-f3ac-4786-b9b8-6aff6d891de8",
   "metadata": {},
   "source": [
    "This code is designed to process recorded data from Intel RealSense cameras stored in bag files. It performs the following operations:\n",
    "\n",
    "Sets up pipelines to read from the RealSense bag file(s)\n",
    "Creates video writers to save color and depth data as AVI videos\n",
    "Uses an alignment object to ensure depth frames match with color frames\n",
    "Continuously processes frames in a loop, where it:\n",
    "\n",
    "1. Retrieves frames from each camera\n",
    "2. Aligns depth to color frames\n",
    "3. Converts frames to numpy arrays for processing\n",
    "4. Applies a colormap to depth images for better visualization\n",
    "5. Saves both color and depth frames to video files\n",
    "6. Displays the frames in OpenCV windows\n",
    "\n",
    "Properly cleans up resources when finished (stopping pipelines, releasing video writers, closing windows)\n",
    "\n",
    "The code handles multiple camera inputs (though currently only one bag file is specified) and includes error handling to gracefully manage any issues retrieving frames. It exits when any camera stops producing frames or when the user presses 'q'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4874fe88-6c85-4873-a9bf-9cf7cd7f1795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# List of bag file paths for the three cameras\n",
    "bag_files = [\n",
    "    \"./scan.bag\"\n",
    "]\n",
    "pipelines = []\n",
    "video_writers_color = []\n",
    "video_writers_depth = []\n",
    "\n",
    "# Video parameters (ensure these match the recorded stream resolution and desired FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "fps = 30\n",
    "frame_width = 640\n",
    "frame_height = 480\n",
    "\n",
    "# Create pipelines for each bag file and initialize video writers\n",
    "for i, bag_file in enumerate(bag_files):\n",
    "    config = rs.config()\n",
    "    # Use enable_all_streams to automatically use the streams recorded in the bag\n",
    "    config.enable_device_from_file(bag_file)\n",
    "    config.enable_all_streams()\n",
    "    \n",
    "    pipeline = rs.pipeline()\n",
    "    try:\n",
    "        pipeline.start(config)\n",
    "        pipelines.append(pipeline)\n",
    "        print(f\"Started pipeline for {bag_file}\")\n",
    "        \n",
    "        # Create VideoWriter objects for color and depth streams\n",
    "        color_filename = f\"camera_{i+1}_color.avi\"\n",
    "        depth_filename = f\"camera_{i+1}_depth.avi\"\n",
    "        writer_color = cv2.VideoWriter(color_filename, fourcc, fps, (frame_width, frame_height))\n",
    "        writer_depth = cv2.VideoWriter(depth_filename, fourcc, fps, (frame_width, frame_height))\n",
    "        video_writers_color.append(writer_color)\n",
    "        video_writers_depth.append(writer_depth)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to start pipeline for {bag_file}: {e}\")\n",
    "\n",
    "# Create an align object to align depth frames to the color stream\n",
    "align = rs.align(rs.stream.color)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        frames_list = []\n",
    "        # Retrieve frames for each bag file pipeline\n",
    "        for idx, pipeline in enumerate(pipelines):\n",
    "            try:\n",
    "                frames = pipeline.wait_for_frames(timeout_ms=5000)\n",
    "                # Align depth to color for this set of frames\n",
    "                aligned_frames = align.process(frames)\n",
    "                frames_list.append(aligned_frames)\n",
    "                print(f\"Camera {idx+1}: Frame received.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Camera {idx+1}: Error retrieving frame: {e}\")\n",
    "                frames_list.append(None)\n",
    "        \n",
    "        # If any camera did not return a frame, we assume the bag has ended or an error occurred.\n",
    "        if any(frame is None for frame in frames_list):\n",
    "            print(\"One or more cameras did not return a frame. Exiting loop.\")\n",
    "            break\n",
    "\n",
    "        # Process, display, and save frames from each camera\n",
    "        for idx, aligned_frames in enumerate(frames_list):\n",
    "            depth_frame = aligned_frames.get_depth_frame()\n",
    "            color_frame = aligned_frames.get_color_frame()\n",
    "\n",
    "            if not depth_frame or not color_frame:\n",
    "                print(f\"Camera {idx+1}: Missing depth or color frame. Skipping this iteration.\")\n",
    "                continue\n",
    "\n",
    "            # Convert frames to numpy arrays\n",
    "            depth_image = np.asanyarray(depth_frame.get_data())\n",
    "            color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "            # For visualization, apply a colormap to the depth image\n",
    "            depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "\n",
    "            # Write the frames to their respective video files\n",
    "            video_writers_color[idx].write(color_image)\n",
    "            video_writers_depth[idx].write(depth_colormap)\n",
    "\n",
    "            # Optionally, display the frames in windows\n",
    "            cv2.imshow(f\"Camera {idx+1} - Color\", color_image)\n",
    "            cv2.imshow(f\"Camera {idx+1} - Depth\", depth_colormap)\n",
    "\n",
    "        # Exit the loop on 'q' key press\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    # Stop all pipelines and release video writers\n",
    "    for pipeline in pipelines:\n",
    "        pipeline.stop()\n",
    "    for writer in video_writers_color:\n",
    "        writer.release()\n",
    "    for writer in video_writers_depth:\n",
    "        writer.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8b5b69-90bb-4dbd-ad52-92d06993c27e",
   "metadata": {},
   "source": [
    "This script is a comprehensive image processing utility designed specifically for the Gaussian-Splatting NeRF preprocessing pipeline. Here's a breakdown of what it does:\n",
    "The script performs intelligent selection of optimal images from a dataset by:\n",
    "\n",
    "Using three different blur detection methods:\n",
    "\n",
    "- Laplacian variance analysis\n",
    "- Fast Fourier Transform (FFT) frequency content analysis\n",
    "- Sobel gradient magnitude measurement\n",
    "\n",
    "Extracting semantic features from images using:\n",
    "\n",
    "- EfficientNet (a deep learning model) as the primary method\n",
    "- OpenCV's ORB detector as a fallback if EfficientNet fails\n",
    "- Ensuring view diversity through:\n",
    "- K-means clustering of image features\n",
    "- Selecting the best (least blurry) image from each cluster\n",
    "\n",
    "\n",
    "### Implementing performance optimizations:\n",
    "\n",
    "- Multiprocessing support for CPU operations\n",
    "- Sequential processing when using GPU to avoid CUDA issues\n",
    "- Graceful fallbacks for error conditions\n",
    "\n",
    "\n",
    "### Handling RGB-D image pairing:\n",
    "\n",
    "- Matching RGB images with corresponding depth maps\n",
    "- Using filename pattern matching to identify pairs\n",
    "- Tracking and reporting any missing depth maps\n",
    "\n",
    "The script is designed to run on Ubuntu and expects a specific directory structure with RGB images in one folder and depth maps in another. It processes all images, selects the top 200 (configurable) based on quality and view diversity, and creates a curated dataset ready for NeRF training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf7d3c1-71b3-4785-a371-f969094972d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Image Processor - Selects optimal RGB images and pairs with depth maps\n",
    "\n",
    "This script:\n",
    "1. Analyzes all images in the current directory\n",
    "2. Detects blur using multiple methods\n",
    "3. Extracts features using EfficientNet for view diversity analysis\n",
    "4. Selects top images with minimal blur and diverse views\n",
    "5. Copies selected images to 'Good Data' folder\n",
    "6. Matches selected RGB images with depth maps from ../Depth\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import multiprocessing\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load EfficientNet for feature extraction\n",
    "def load_efficientnet():\n",
    "    try:\n",
    "        model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "        model.eval()\n",
    "        model = model.to(device)\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load EfficientNet: {e}\")\n",
    "        print(\"Falling back to OpenCV-based feature extraction\")\n",
    "        return None\n",
    "\n",
    "# Preprocessing transforms for EfficientNet\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def calculate_blur_metrics(image_path):\n",
    "    \"\"\"Calculate blur metrics using multiple methods\"\"\"\n",
    "    try:\n",
    "        # Read image\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            return None, None, None\n",
    "        \n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Method 1: Laplacian variance (lower values indicate more blur)\n",
    "        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "        \n",
    "        # Method 2: FFT-based blur detection\n",
    "        f = np.fft.fft2(gray)\n",
    "        fshift = np.fft.fftshift(f)\n",
    "        magnitude_spectrum = 20 * np.log(np.abs(fshift) + 1)\n",
    "        \n",
    "        h, w = gray.shape\n",
    "        center_y, center_x = h//2, w//2\n",
    "        \n",
    "        mask = np.ones((h, w), np.uint8)\n",
    "        center_region = 20\n",
    "        mask[center_y-center_region:center_y+center_region, center_x-center_region:center_x+center_region] = 0\n",
    "        \n",
    "        high_freq_content = np.sum(magnitude_spectrum * mask) / np.sum(mask)\n",
    "        \n",
    "        # Method 3: Sobel gradients\n",
    "        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        sobel_mag = np.sqrt(sobelx**2 + sobely**2)\n",
    "        sobel_mean = np.mean(sobel_mag)\n",
    "        \n",
    "        return laplacian_var, high_freq_content, sobel_mean\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "def extract_features_cv(image_path):\n",
    "    \"\"\"Extract features using OpenCV ORB (fallback method)\"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            return None\n",
    "        \n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        orb = cv2.ORB_create(nfeatures=500)\n",
    "        keypoints, descriptors = orb.detectAndCompute(img, None)\n",
    "        \n",
    "        if descriptors is None or len(descriptors) == 0:\n",
    "            return np.zeros((1, 32), dtype=np.float32)\n",
    "        \n",
    "        return np.mean(descriptors, axis=0).reshape(1, -1).astype(np.float32)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting CV features from {image_path}: {e}\")\n",
    "        return np.zeros((1, 32), dtype=np.float32)\n",
    "\n",
    "def extract_features_efficientnet(image_path, model):\n",
    "    \"\"\"Extract features using EfficientNet\"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            return None\n",
    "        \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            features = model.extract_features(img_tensor)\n",
    "            features = torch.nn.functional.adaptive_avg_pool2d(features, 1)\n",
    "            features = features.squeeze().cpu().numpy()\n",
    "        \n",
    "        return features.reshape(1, -1).astype(np.float32)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting EfficientNet features from {image_path}: {e}\")\n",
    "        if model is not None:\n",
    "            return extract_features_cv(image_path)\n",
    "        else:\n",
    "            return np.zeros((1, 32), dtype=np.float32)\n",
    "\n",
    "def process_image(args):\n",
    "    img_path, model = args\n",
    "    \n",
    "    laplacian_var, high_freq_content, sobel_mean = calculate_blur_metrics(img_path)\n",
    "    \n",
    "    if laplacian_var is None:\n",
    "        return None\n",
    "    \n",
    "    if model is not None:\n",
    "        features = extract_features_efficientnet(img_path, model)\n",
    "    else:\n",
    "        features = extract_features_cv(img_path)\n",
    "    \n",
    "    if features is not None:\n",
    "        return {\n",
    "            'path': img_path,\n",
    "            'laplacian_var': laplacian_var,\n",
    "            'high_freq_content': high_freq_content,\n",
    "            'sobel_mean': sobel_mean,\n",
    "            'features': features\n",
    "        }\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Alternative approach without using ProcessPoolExecutor\n",
    "def process_single_image(img_path, model=None):\n",
    "    return process_image((img_path, model))\n",
    "\n",
    "def process_image_directory_sequential(directory_path='.', model=None):\n",
    "    \"\"\"Process images sequentially without multiprocessing\"\"\"\n",
    "    image_data = []\n",
    "    \n",
    "    image_files = [f for f in os.listdir(directory_path) \n",
    "                  if os.path.isfile(os.path.join(directory_path, f)) and \n",
    "                  f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.webp'))]\n",
    "    \n",
    "    print(f\"Found {len(image_files)} images in {directory_path}\")\n",
    "    print(\"Processing images sequentially...\")\n",
    "    \n",
    "    for img_file in tqdm(image_files, desc=\"Processing images\"):\n",
    "        img_path = os.path.join(directory_path, img_file)\n",
    "        result = process_image((img_path, model))\n",
    "        if result is not None:\n",
    "            image_data.append(result)\n",
    "    \n",
    "    print(f\"Successfully processed {len(image_data)} images\")\n",
    "    return image_data\n",
    "\n",
    "def process_image_directory(directory_path='.', model=None):\n",
    "    \"\"\"Process images with multiprocessing if possible, otherwise fall back to sequential\"\"\"\n",
    "    try:\n",
    "        # First try using spawn method\n",
    "        multiprocessing.set_start_method('spawn', force=True)\n",
    "        \n",
    "        image_data = []\n",
    "        \n",
    "        image_files = [f for f in os.listdir(directory_path) \n",
    "                      if os.path.isfile(os.path.join(directory_path, f)) and \n",
    "                      f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.webp'))]\n",
    "        \n",
    "        print(f\"Found {len(image_files)} images in {directory_path}\")\n",
    "        \n",
    "        # For GPU processing, use sequential processing to avoid CUDA issues\n",
    "        if torch.cuda.is_available():\n",
    "            print(\"CUDA detected. Using sequential processing to avoid CUDA initialization issues.\")\n",
    "            return process_image_directory_sequential(directory_path, model)\n",
    "        \n",
    "        # For CPU processing, we can still use multiprocessing\n",
    "        num_workers = min(multiprocessing.cpu_count(), 8)\n",
    "        print(f\"Using {num_workers} worker processes\")\n",
    "        \n",
    "        # Use a multiprocessing.Pool directly instead of ProcessPoolExecutor\n",
    "        with multiprocessing.Pool(processes=num_workers) as pool:\n",
    "            args_list = [(os.path.join(directory_path, img_file), model) for img_file in image_files]\n",
    "            results = list(tqdm(pool.imap(process_image, args_list), total=len(args_list), desc=\"Processing images\"))\n",
    "            \n",
    "            for result in results:\n",
    "                if result is not None:\n",
    "                    image_data.append(result)\n",
    "        \n",
    "        print(f\"Successfully processed {len(image_data)} images\")\n",
    "        return image_data\n",
    "        \n",
    "    except (AttributeError, RuntimeError) as e:\n",
    "        print(f\"Multiprocessing error: {e}\")\n",
    "        print(\"Falling back to sequential processing...\")\n",
    "        return process_image_directory_sequential(directory_path, model)\n",
    "\n",
    "def select_top_images(image_data, num_to_select=300):\n",
    "    if len(image_data) <= num_to_select:\n",
    "        return [data['path'] for data in image_data]\n",
    "    \n",
    "    laplacian_vars = np.array([data['laplacian_var'] for data in image_data])\n",
    "    high_freq_contents = np.array([data['high_freq_content'] for data in image_data])\n",
    "    sobel_means = np.array([data['sobel_mean'] for data in image_data])\n",
    "    \n",
    "    def normalize(x):\n",
    "        return (x - x.min()) / (x.max() - x.min() + 1e-10)\n",
    "    \n",
    "    norm_laplacian = normalize(laplacian_vars)\n",
    "    norm_high_freq = normalize(high_freq_contents)\n",
    "    norm_sobel = normalize(sobel_means)\n",
    "    \n",
    "    blur_scores = (norm_laplacian + norm_high_freq + norm_sobel) / 3\n",
    "    \n",
    "    feature_matrix = np.vstack([data['features'] for data in image_data])\n",
    "    \n",
    "    n_clusters = min(num_to_select, len(image_data))\n",
    "    print(f\"Clustering images into {n_clusters} groups...\")\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    clusters = kmeans.fit_predict(feature_matrix)\n",
    "    unique_clusters = np.unique(clusters)\n",
    "    \n",
    "    selected_images = []\n",
    "    images_per_cluster = {cluster_id: 1 for cluster_id in unique_clusters}\n",
    "    \n",
    "    if len(images_per_cluster) < num_to_select:\n",
    "        print(f\"Warning: Only {len(images_per_cluster)} unique clusters found\")\n",
    "    \n",
    "    for cluster_id in unique_clusters:\n",
    "        cluster_indices = np.where(clusters == cluster_id)[0]\n",
    "        cluster_blur_scores = blur_scores[cluster_indices]\n",
    "        sorted_indices = cluster_indices[np.argsort(-cluster_blur_scores)]\n",
    "        \n",
    "        top_n = images_per_cluster[cluster_id]\n",
    "        for idx in sorted_indices[:top_n]:\n",
    "            selected_images.append(image_data[idx]['path'])\n",
    "    \n",
    "    return selected_images\n",
    "\n",
    "def main():\n",
    "    print(\"Loading EfficientNet for feature extraction...\")\n",
    "    model = load_efficientnet()\n",
    "    \n",
    "    image_directory = \"/home/aaronmcafee/Documents/bigVid/RGB\"\n",
    "    num_to_select = 200\n",
    "    output_dir = \"/home/aaronmcafee/Documents/bigVid/good\"\n",
    "    \n",
    "    print(\"Starting image analysis...\")\n",
    "    image_data = process_image_directory(image_directory, model)\n",
    "    \n",
    "    if len(image_data) == 0:\n",
    "        print(\"No images were successfully processed. Please check the images in the directory.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Selecting top {num_to_select} images...\")\n",
    "    selected_images = select_top_images(image_data, num_to_select)\n",
    "    \n",
    "    print(f\"Selected {len(selected_images)} out of {len(image_data)} images\")\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"Created output directory: {output_dir}\")\n",
    "    \n",
    "    print(f\"Copying selected images to {output_dir}...\")\n",
    "    for i, img_path in enumerate(tqdm(selected_images, desc=\"Copying files\")):\n",
    "        filename = os.path.basename(img_path)\n",
    "        dst = os.path.join(output_dir, f\"{i:04d}_{filename}\")\n",
    "        shutil.copy(img_path, dst)\n",
    "    \n",
    "    # Depth map matching logic\n",
    "    print(\"\\nMatching depth maps...\")\n",
    "    depth_folder = os.path.abspath(os.path.join(image_directory, '../Depth'))\n",
    "    if not os.path.exists(depth_folder):\n",
    "        print(f\"Depth folder not found: {depth_folder}\")\n",
    "    else:\n",
    "        paired_count = 0\n",
    "        missing_depths = []\n",
    "        \n",
    "        for img_path in tqdm(selected_images, desc=\"Matching depth maps\"):\n",
    "            filename = os.path.basename(img_path)\n",
    "            match = re.search(r'v2_(\\d+)\\.png$', filename)\n",
    "            if not match:\n",
    "                print(f\"Warning: Could not extract serial number from {filename}, skipping\")\n",
    "                continue\n",
    "            serial = match.group(1)\n",
    "            depth_file = f\"depth_{serial}.png\"\n",
    "            depth_path = os.path.join(depth_folder, depth_file)\n",
    "            \n",
    "            if not os.path.exists(depth_path):\n",
    "                missing_depths.append(filename)\n",
    "                continue\n",
    "            \n",
    "            depth_dest = os.path.join(output_dir, depth_file)\n",
    "            shutil.copy2(depth_path, depth_dest)\n",
    "            paired_count += 1\n",
    "        \n",
    "        print(f\"Successfully paired {paired_count} RGB images with depth maps\")\n",
    "        if missing_depths:\n",
    "            print(f\"Warning: {len(missing_depths)} depth maps missing\")\n",
    "            missing_file = os.path.join(output_dir, \"missing_depth_maps.txt\")\n",
    "            with open(missing_file, 'w') as f:\n",
    "                for name in missing_depths:\n",
    "                    f.write(f\"{name}\\n\")\n",
    "            print(f\"Missing depth maps listed in {missing_file}\")\n",
    "    \n",
    "    print(f\"Done! {len(selected_images)} images have been copied to {output_dir}\")\n",
    "    print(f\"Selected {len(selected_images)/len(image_data):.1%} of the original images\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nProcess interrupted by user\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
