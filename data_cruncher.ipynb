{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fbb7d8b-a905-426c-aff6-b2fb95aaef07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EfficientNet for feature extraction...\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Starting image analysis...\n",
      "Found 2934 images in /home/aaronmcafee/Documents/bigVid/RGB\n",
      "CUDA detected. Using sequential processing to avoid CUDA initialization issues.\n",
      "Found 2934 images in /home/aaronmcafee/Documents/bigVid/RGB\n",
      "Processing images sequentially...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|████████████████████| 2934/2934 [01:35<00:00, 30.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 2934 images\n",
      "Selecting top 200 images...\n",
      "Clustering images into 200 groups...\n",
      "Selected 200 out of 2934 images\n",
      "Copying selected images to /home/aaronmcafee/Documents/bigVid/good...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 100%|████████████████████████| 200/200 [00:00<00:00, 2490.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matching depth maps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching depth maps: 100%|██████████████████| 200/200 [00:00<00:00, 2258.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully paired 200 RGB images with depth maps\n",
      "Done! 200 images have been copied to /home/aaronmcafee/Documents/bigVid/good\n",
      "Selected 6.8% of the original images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Image Processor - Selects optimal RGB images and pairs with depth maps\n",
    "\n",
    "This script:\n",
    "1. Analyzes all images in the current directory\n",
    "2. Detects blur using multiple methods\n",
    "3. Extracts features using EfficientNet for view diversity analysis\n",
    "4. Selects top images with minimal blur and diverse views\n",
    "5. Copies selected images to 'Good Data' folder\n",
    "6. Matches selected RGB images with depth maps from ../Depth\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import multiprocessing\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load EfficientNet for feature extraction\n",
    "def load_efficientnet():\n",
    "    try:\n",
    "        model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "        model.eval()\n",
    "        model = model.to(device)\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load EfficientNet: {e}\")\n",
    "        print(\"Falling back to OpenCV-based feature extraction\")\n",
    "        return None\n",
    "\n",
    "# Preprocessing transforms for EfficientNet\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def calculate_blur_metrics(image_path):\n",
    "    \"\"\"Calculate blur metrics using multiple methods\"\"\"\n",
    "    try:\n",
    "        # Read image\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            return None, None, None\n",
    "        \n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Method 1: Laplacian variance (lower values indicate more blur)\n",
    "        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "        \n",
    "        # Method 2: FFT-based blur detection\n",
    "        f = np.fft.fft2(gray)\n",
    "        fshift = np.fft.fftshift(f)\n",
    "        magnitude_spectrum = 20 * np.log(np.abs(fshift) + 1)\n",
    "        \n",
    "        h, w = gray.shape\n",
    "        center_y, center_x = h//2, w//2\n",
    "        \n",
    "        mask = np.ones((h, w), np.uint8)\n",
    "        center_region = 20\n",
    "        mask[center_y-center_region:center_y+center_region, center_x-center_region:center_x+center_region] = 0\n",
    "        \n",
    "        high_freq_content = np.sum(magnitude_spectrum * mask) / np.sum(mask)\n",
    "        \n",
    "        # Method 3: Sobel gradients\n",
    "        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        sobel_mag = np.sqrt(sobelx**2 + sobely**2)\n",
    "        sobel_mean = np.mean(sobel_mag)\n",
    "        \n",
    "        return laplacian_var, high_freq_content, sobel_mean\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "def extract_features_cv(image_path):\n",
    "    \"\"\"Extract features using OpenCV ORB (fallback method)\"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            return None\n",
    "        \n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        orb = cv2.ORB_create(nfeatures=500)\n",
    "        keypoints, descriptors = orb.detectAndCompute(img, None)\n",
    "        \n",
    "        if descriptors is None or len(descriptors) == 0:\n",
    "            return np.zeros((1, 32), dtype=np.float32)\n",
    "        \n",
    "        return np.mean(descriptors, axis=0).reshape(1, -1).astype(np.float32)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting CV features from {image_path}: {e}\")\n",
    "        return np.zeros((1, 32), dtype=np.float32)\n",
    "\n",
    "def extract_features_efficientnet(image_path, model):\n",
    "    \"\"\"Extract features using EfficientNet\"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            return None\n",
    "        \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            features = model.extract_features(img_tensor)\n",
    "            features = torch.nn.functional.adaptive_avg_pool2d(features, 1)\n",
    "            features = features.squeeze().cpu().numpy()\n",
    "        \n",
    "        return features.reshape(1, -1).astype(np.float32)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting EfficientNet features from {image_path}: {e}\")\n",
    "        if model is not None:\n",
    "            return extract_features_cv(image_path)\n",
    "        else:\n",
    "            return np.zeros((1, 32), dtype=np.float32)\n",
    "\n",
    "def process_image(args):\n",
    "    img_path, model = args\n",
    "    \n",
    "    laplacian_var, high_freq_content, sobel_mean = calculate_blur_metrics(img_path)\n",
    "    \n",
    "    if laplacian_var is None:\n",
    "        return None\n",
    "    \n",
    "    if model is not None:\n",
    "        features = extract_features_efficientnet(img_path, model)\n",
    "    else:\n",
    "        features = extract_features_cv(img_path)\n",
    "    \n",
    "    if features is not None:\n",
    "        return {\n",
    "            'path': img_path,\n",
    "            'laplacian_var': laplacian_var,\n",
    "            'high_freq_content': high_freq_content,\n",
    "            'sobel_mean': sobel_mean,\n",
    "            'features': features\n",
    "        }\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Alternative approach without using ProcessPoolExecutor\n",
    "def process_single_image(img_path, model=None):\n",
    "    return process_image((img_path, model))\n",
    "\n",
    "def process_image_directory_sequential(directory_path='.', model=None):\n",
    "    \"\"\"Process images sequentially without multiprocessing\"\"\"\n",
    "    image_data = []\n",
    "    \n",
    "    image_files = [f for f in os.listdir(directory_path) \n",
    "                  if os.path.isfile(os.path.join(directory_path, f)) and \n",
    "                  f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.webp'))]\n",
    "    \n",
    "    print(f\"Found {len(image_files)} images in {directory_path}\")\n",
    "    print(\"Processing images sequentially...\")\n",
    "    \n",
    "    for img_file in tqdm(image_files, desc=\"Processing images\"):\n",
    "        img_path = os.path.join(directory_path, img_file)\n",
    "        result = process_image((img_path, model))\n",
    "        if result is not None:\n",
    "            image_data.append(result)\n",
    "    \n",
    "    print(f\"Successfully processed {len(image_data)} images\")\n",
    "    return image_data\n",
    "\n",
    "def process_image_directory(directory_path='.', model=None):\n",
    "    \"\"\"Process images with multiprocessing if possible, otherwise fall back to sequential\"\"\"\n",
    "    try:\n",
    "        # First try using spawn method\n",
    "        multiprocessing.set_start_method('spawn', force=True)\n",
    "        \n",
    "        image_data = []\n",
    "        \n",
    "        image_files = [f for f in os.listdir(directory_path) \n",
    "                      if os.path.isfile(os.path.join(directory_path, f)) and \n",
    "                      f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.webp'))]\n",
    "        \n",
    "        print(f\"Found {len(image_files)} images in {directory_path}\")\n",
    "        \n",
    "        # For GPU processing, use sequential processing to avoid CUDA issues\n",
    "        if torch.cuda.is_available():\n",
    "            print(\"CUDA detected. Using sequential processing to avoid CUDA initialization issues.\")\n",
    "            return process_image_directory_sequential(directory_path, model)\n",
    "        \n",
    "        # For CPU processing, we can still use multiprocessing\n",
    "        num_workers = min(multiprocessing.cpu_count(), 8)\n",
    "        print(f\"Using {num_workers} worker processes\")\n",
    "        \n",
    "        # Use a multiprocessing.Pool directly instead of ProcessPoolExecutor\n",
    "        with multiprocessing.Pool(processes=num_workers) as pool:\n",
    "            args_list = [(os.path.join(directory_path, img_file), model) for img_file in image_files]\n",
    "            results = list(tqdm(pool.imap(process_image, args_list), total=len(args_list), desc=\"Processing images\"))\n",
    "            \n",
    "            for result in results:\n",
    "                if result is not None:\n",
    "                    image_data.append(result)\n",
    "        \n",
    "        print(f\"Successfully processed {len(image_data)} images\")\n",
    "        return image_data\n",
    "        \n",
    "    except (AttributeError, RuntimeError) as e:\n",
    "        print(f\"Multiprocessing error: {e}\")\n",
    "        print(\"Falling back to sequential processing...\")\n",
    "        return process_image_directory_sequential(directory_path, model)\n",
    "\n",
    "def select_top_images(image_data, num_to_select=300):\n",
    "    if len(image_data) <= num_to_select:\n",
    "        return [data['path'] for data in image_data]\n",
    "    \n",
    "    laplacian_vars = np.array([data['laplacian_var'] for data in image_data])\n",
    "    high_freq_contents = np.array([data['high_freq_content'] for data in image_data])\n",
    "    sobel_means = np.array([data['sobel_mean'] for data in image_data])\n",
    "    \n",
    "    def normalize(x):\n",
    "        return (x - x.min()) / (x.max() - x.min() + 1e-10)\n",
    "    \n",
    "    norm_laplacian = normalize(laplacian_vars)\n",
    "    norm_high_freq = normalize(high_freq_contents)\n",
    "    norm_sobel = normalize(sobel_means)\n",
    "    \n",
    "    blur_scores = (norm_laplacian + norm_high_freq + norm_sobel) / 3\n",
    "    \n",
    "    feature_matrix = np.vstack([data['features'] for data in image_data])\n",
    "    \n",
    "    n_clusters = min(num_to_select, len(image_data))\n",
    "    print(f\"Clustering images into {n_clusters} groups...\")\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    clusters = kmeans.fit_predict(feature_matrix)\n",
    "    unique_clusters = np.unique(clusters)\n",
    "    \n",
    "    selected_images = []\n",
    "    images_per_cluster = {cluster_id: 1 for cluster_id in unique_clusters}\n",
    "    \n",
    "    if len(images_per_cluster) < num_to_select:\n",
    "        print(f\"Warning: Only {len(images_per_cluster)} unique clusters found\")\n",
    "    \n",
    "    for cluster_id in unique_clusters:\n",
    "        cluster_indices = np.where(clusters == cluster_id)[0]\n",
    "        cluster_blur_scores = blur_scores[cluster_indices]\n",
    "        sorted_indices = cluster_indices[np.argsort(-cluster_blur_scores)]\n",
    "        \n",
    "        top_n = images_per_cluster[cluster_id]\n",
    "        for idx in sorted_indices[:top_n]:\n",
    "            selected_images.append(image_data[idx]['path'])\n",
    "    \n",
    "    return selected_images\n",
    "\n",
    "def main():\n",
    "    print(\"Loading EfficientNet for feature extraction...\")\n",
    "    model = load_efficientnet()\n",
    "    \n",
    "    image_directory = \"/home/aaronmcafee/Documents/bigVid/RGB\"\n",
    "    num_to_select = 200\n",
    "    output_dir = \"/home/aaronmcafee/Documents/bigVid/good\"\n",
    "    \n",
    "    print(\"Starting image analysis...\")\n",
    "    image_data = process_image_directory(image_directory, model)\n",
    "    \n",
    "    if len(image_data) == 0:\n",
    "        print(\"No images were successfully processed. Please check the images in the directory.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Selecting top {num_to_select} images...\")\n",
    "    selected_images = select_top_images(image_data, num_to_select)\n",
    "    \n",
    "    print(f\"Selected {len(selected_images)} out of {len(image_data)} images\")\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"Created output directory: {output_dir}\")\n",
    "    \n",
    "    print(f\"Copying selected images to {output_dir}...\")\n",
    "    for i, img_path in enumerate(tqdm(selected_images, desc=\"Copying files\")):\n",
    "        filename = os.path.basename(img_path)\n",
    "        dst = os.path.join(output_dir, f\"{i:04d}_{filename}\")\n",
    "        shutil.copy(img_path, dst)\n",
    "    \n",
    "    # Depth map matching logic\n",
    "    print(\"\\nMatching depth maps...\")\n",
    "    depth_folder = os.path.abspath(os.path.join(image_directory, '../Depth'))\n",
    "    if not os.path.exists(depth_folder):\n",
    "        print(f\"Depth folder not found: {depth_folder}\")\n",
    "    else:\n",
    "        paired_count = 0\n",
    "        missing_depths = []\n",
    "        \n",
    "        for img_path in tqdm(selected_images, desc=\"Matching depth maps\"):\n",
    "            filename = os.path.basename(img_path)\n",
    "            match = re.search(r'v2_(\\d+)\\.png$', filename)\n",
    "            if not match:\n",
    "                print(f\"Warning: Could not extract serial number from {filename}, skipping\")\n",
    "                continue\n",
    "            serial = match.group(1)\n",
    "            depth_file = f\"depth_{serial}.png\"\n",
    "            depth_path = os.path.join(depth_folder, depth_file)\n",
    "            \n",
    "            if not os.path.exists(depth_path):\n",
    "                missing_depths.append(filename)\n",
    "                continue\n",
    "            \n",
    "            depth_dest = os.path.join(output_dir, depth_file)\n",
    "            shutil.copy2(depth_path, depth_dest)\n",
    "            paired_count += 1\n",
    "        \n",
    "        print(f\"Successfully paired {paired_count} RGB images with depth maps\")\n",
    "        if missing_depths:\n",
    "            print(f\"Warning: {len(missing_depths)} depth maps missing\")\n",
    "            missing_file = os.path.join(output_dir, \"missing_depth_maps.txt\")\n",
    "            with open(missing_file, 'w') as f:\n",
    "                for name in missing_depths:\n",
    "                    f.write(f\"{name}\\n\")\n",
    "            print(f\"Missing depth maps listed in {missing_file}\")\n",
    "    \n",
    "    print(f\"Done! {len(selected_images)} images have been copied to {output_dir}\")\n",
    "    print(f\"Selected {len(selected_images)/len(image_data):.1%} of the original images\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nProcess interrupted by user\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f01a04-5a3a-4cf8-8bb5-9b1516f3dc41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45504b0-1f22-462e-a0c4-fff800a78e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
